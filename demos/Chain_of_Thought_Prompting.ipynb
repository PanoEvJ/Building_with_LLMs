{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UIuhLOcmCdyR"
      },
      "source": [
        "### Chain of Thought Prompting\n",
        "\n",
        "Based on this [research](https://arxiv.org/abs/2201.11903) - chain of thought prompting improved the models ability to perform more robustly on complex reasoning tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2y8NcRnD8aa",
        "outputId": "03033dfa-8fb4-4858-a571-4dbfa1aa163a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpnsDCfEbsqS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# set the OPENAI_API_KEY environment variable\n",
        "openai.api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSQMFfWKbsqT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def get_response(messages: str) -> str:\n",
        "    return openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )[\"choices\"][0][\"message\"]\n",
        "\n",
        "def wrap_prompt(message: str, role: str) -> dict:\n",
        "    return {\"role\": role, \"content\": message}\n",
        "\n",
        "def m_print(message: str) -> str:\n",
        "    display(Markdown(message[\"content\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "7aEd_p1sbsqT",
        "outputId": "a279337e-6fb4-4771-a10c-7285cdb30425"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Neither of these options is possible since they both require an unrealistic amount of travel time. A more realistic option would need to be provided to accurately compare travel times."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = wrap_prompt(\"\"\"Which is a faster way to get to work?\n",
        "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
        "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\"\"\", \"user\")\n",
        "\n",
        "m_print(get_response([prompt]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "QI89eB4yFS4k",
        "outputId": "c0a9a28a-fb88-4872-aecc-0eccadb1a3f2"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "It is unlikely that Option 1 is a realistic option, as a 1000-minute bus ride would take over 16 hours. Therefore, Option 2 is the faster way to get to work."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = wrap_prompt(\"\"\"Which is a faster way to get home?\n",
        "Option 1: Take an 10 minutes bus, then an 40 minute bus, and finally a 10 minute train.\n",
        "Option 2: Take a 90 minutes train, then a 45 minute bike ride, and finally a 10 minute bus.\n",
        "Option 1 will take 10+40+10 = 60 minutes.\n",
        "Option 2 will take 90+45+10=145 minutes.\n",
        "Since Option 1 takes 60 minutes and Option 2 takes 145 minutes, Option 1 is faster.\n",
        "\n",
        "Which is a faster way to get to work?\n",
        "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
        "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\"\"\", \"user\")\n",
        "\n",
        "m_print(get_response([prompt]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "y5RAf8AZFiGI",
        "outputId": "df9626c7-e894-47c1-c0d0-9b4f08bd8b94"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "As an AI language model, I believe there is an error in the given times for both options. It is more likely that the first option refers to a 10-minute bus ride, not 1000 minutes, and the second option refers to an 80-minute bus ride, not 800 minutes.\n",
              "\n",
              "Assuming the corrected times, it is clear that Option 1 is the faster way to get to work. Here are the steps:\n",
              "\n",
              "1. Take a 10-minute bus ride to the train station.\n",
              "2. Take a half hour train ride to a stop near work.\n",
              "3. Take a 10-minute bike ride from the train station to work.\n",
              "\n",
              "Total time for Option 1: 50 minutes.\n",
              "\n",
              "1. Take an 80-minute bus ride to the train station.\n",
              "2. Take an hour train ride to a stop near work.\n",
              "3. Take a 30-minute bike ride from the train station to work.\n",
              "\n",
              "Total time for Option 2: 2 hours.\n",
              "\n",
              "Therefore, Option 1 is much faster than Option 2."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = wrap_prompt(\"\"\"Which is a faster way to get to work? Think through your answer step by step.\n",
        "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
        "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\"\"\", \"user\")\n",
        "\n",
        "m_print(get_response([prompt]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "open_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
